{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import all modules and define frequently used functions\n",
    "\n",
    "import os, csv\n",
    "import math\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors as CD\n",
    "\n",
    "def get_text_from_file(file_name):\n",
    "\n",
    "   f = open(file_name, \"r\")\n",
    "   lines = f.readlines()\n",
    "   f.close()\n",
    "\n",
    "   return lines\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS: Define X as the \"main atom\" of interest in the functional group (B and Br are implemented), if a file prefix was used define the variable correspondingly, and finally define the folder path.\n",
    "\n",
    "PATH = \"/Users/lhoff/Desktop/calculations/results/inp_220201/\"\n",
    "X = \"B\"\n",
    "file_prefix = \"BA\"\n",
    "output_name = \"output_file_name\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block first reads in th smiles from the dataset file used for the featurization, then it uses RDkit to get molecular weights and a custom parser to extract \n",
    "# the computed featurization data from the orca output files. Then it goes through the results.csv file which should be present in the results folder and contains\n",
    "# additional data, e.g. Vbur, etc.\n",
    "\n",
    "os.chdir(PATH)   # <<------- PATH points at the root folder of all results\n",
    "\n",
    "collected_data = {}\n",
    "smiles = get_text_from_file(\"dataset.txt\")\n",
    "\n",
    "for i in range(len(smiles)):\n",
    "    smile = smiles[i].rstrip(\"\\n\")\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    mol_weight = CD.ExactMolWt(mol)\n",
    "    collected_data[int(i)] = {\"SMILES\": smile}\n",
    "    collected_data[int(i)][\"MolWeight\"] = float(mol_weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params_of_interest = [\n",
    "    {\n",
    "        \"keyword\": \"FINAL SINGLE POINT ENERGY\",\n",
    "        \"abbr\": \"FSPE\",\n",
    "        \"y_offset\": 0,\n",
    "        \"keep_index\": [4]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"DIPOLE MOMENT\",\n",
    "        \"abbr\": \"DIPOLE\",\n",
    "        \"y_offset\": 9,\n",
    "        \"keep_index\": [3]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"CHEMICAL SHIELDING SUMMARY\",\n",
    "        \"abbr\": \"CHEM SHIELD\",\n",
    "        \"y_offset\": 6,\n",
    "        \"keep_index\": [0, 1, 2]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"HIRSHFELD ANALYSIS\",\n",
    "        \"abbr\": \"HIRSHFELD\",\n",
    "        \"y_offset\": 7,\n",
    "        \"keep_index\": [0, 1, 2]\n",
    "    },\n",
    "    {\n",
    "        \"keyword\": \"LOEWDIN ATOMIC CHARGES\",\n",
    "        \"abbr\": \"LOEWDIN\",\n",
    "        \"y_offset\": 2,\n",
    "        \"keep_index\": [0, 1, 3]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"MULLIKEN ATOMIC CHARGES\",\n",
    "        \"abbr\": \"MULLIKEN\",\n",
    "        \"y_offset\": 2,\n",
    "        \"keep_index\": [0, 1, 3]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"MAYER POPULATION ANALYSIS\",\n",
    "        \"abbr\": \"MAYER\",\n",
    "        \"y_offset\": 11,\n",
    "        \"keep_index\": [0, 1, 3]\n",
    "    }, \n",
    "    {\n",
    "        \"keyword\": \"ORBITAL ENERGIES\",\n",
    "        \"abbr\": \"HOMO/LUMO\",\n",
    "        \"y_offset\": 4,\n",
    "        \"keep_index\": [0, 1] # not really keeping two, but using this as exception\n",
    "    }, \n",
    "]\n",
    "\n",
    "os.chdir(\"results\")\n",
    "\n",
    "for key in collected_data.keys():\n",
    "    \n",
    "    os.chdir(str(key) + \"/orca\")\n",
    "    results = get_text_from_file(\"out_param_\" + str(key) + \".out\")\n",
    "\n",
    "    number_of_atoms = int(get_text_from_file(file_prefix + \"_\" + str(key) + \".xyz\")[0].split()[0])\n",
    "\n",
    "    for i in range(len(results)): # for every line of text in the orca.out file\n",
    "\n",
    "        for param in params_of_interest: # we check against every defined parameter of interest\n",
    "            if param[\"keyword\"] in results[i]: # if the defined keyword is contained in the line of text\n",
    "                \n",
    "                if len(param[\"keep_index\"]) == 1:\n",
    "                    arr = results[i + param[\"y_offset\"]].split()\n",
    "                    collected_data[key][param[\"abbr\"]] = float(arr[param[\"keep_index\"][0]])\n",
    "                    \n",
    "                elif len(param[\"keep_index\"]) == 2:\n",
    "                    \n",
    "                    for j in range(9999):\n",
    "                        arr = results[i + param[\"y_offset\"] + j].split()\n",
    "                            \n",
    "                        if float(arr[1]) == 0:\n",
    "                            \n",
    "                            previous_arr = results[i + param[\"y_offset\"] + j - 1].split()\n",
    "                            \n",
    "                            homo = float(previous_arr[3])\n",
    "                            lumo = float(arr[3])\n",
    "\n",
    "                            collected_data[key][\"HOMO\"] = homo\n",
    "                            collected_data[key][\"LUMO\"] = lumo\n",
    "\n",
    "                            collected_data[key][\"E NEG\"] = -0.5 * (lumo + homo)\n",
    "                            collected_data[key][\"HARDNESS\"] = 0.5 * (lumo - homo)\n",
    "                            collected_data[key][\"SOFTNESS\"] = 1.0/collected_data[key][\"HARDNESS\"]\n",
    "\n",
    "                            break\n",
    "\n",
    "                elif len(param[\"keep_index\"]) == 3:\n",
    "\n",
    "                    collected_data[key][param[\"abbr\"]] = {}\n",
    "\n",
    "                    for j in range(number_of_atoms):\n",
    "                        arr = results[i + param[\"y_offset\"] + j].split()\n",
    "\n",
    "                        if len(arr) == 0: # fix for NMR spectra potentially not having data for all atoms\n",
    "                            break\n",
    "\n",
    "                        elif len(arr) == 3: # fix for LOEWDIN charges with 2 letter atoms\n",
    "                            arr.append(arr[len(arr) - 1])\n",
    "                            arr[1] = arr[1][:2]\n",
    "\n",
    "                        atom_index = arr[param[\"keep_index\"][0]]\n",
    "                        \n",
    "                        collected_data[key][param[\"abbr\"]][int(atom_index)] = {\n",
    "\n",
    "                            \"atom_type\": arr[param[\"keep_index\"][1]],\n",
    "                            \"value\": float(arr[param[\"keep_index\"][2]])\n",
    "\n",
    "                        }\n",
    "\n",
    "                else:\n",
    "                    print(\"weird\" + str(arr))\n",
    "                \n",
    "                                \n",
    "    os.chdir(\"../../\")\n",
    "\n",
    "\n",
    "t = open(\"results.csv\", \"r\")\n",
    "tt = t.readlines()\n",
    "t.close()\n",
    "\n",
    "\n",
    "properties = tt[0].split(\",\")\n",
    "properties.pop(0)\n",
    "properties[len(properties)-1] = properties[len(properties)-1][0:len(properties[len(properties)-1])-1]\n",
    "\n",
    "tt.pop(0)\n",
    "\n",
    "for line in tt:\n",
    "    values = line.split(\",\")\n",
    "    values[len(values)-1] = values[len(values)-1][0:len(values[len(values)-1])-1]\n",
    "\n",
    "    key = int(values[0])\n",
    "    values.pop(0)\n",
    "\n",
    "    for i, value in enumerate(values):\n",
    "        collected_data[key][properties[i]] = float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA511 is missing the Vbur property\n",
      "BA604 is missing the Vbur property\n",
      "BA967 is missing the HOMO property\n",
      "BA967 is missing the LUMO property\n",
      "BA967 is missing the E NEG property\n",
      "BA967 is missing the HARDNESS property\n",
      "BA967 is missing the SOFTNESS property\n",
      "BA967 is missing the MULLIKEN property\n",
      "BA967 is missing the LOEWDIN property\n",
      "BA967 is missing the MAYER property\n",
      "BA967 is missing the HIRSHFELD property\n",
      "BA967 is missing the FSPE property\n",
      "BA967 is missing the DIPOLE property\n",
      "BA967 is missing the CHEM SHIELD property\n",
      "BA1424 is missing the Vbur property\n",
      "BA1565 is missing the Vbur property\n",
      "BA1872 is missing the Vbur property\n",
      "BA1960 is missing the Vbur property\n",
      "BA2321 is missing the Vbur property\n",
      "BA2458 is missing the Vbur property\n",
      "BA2464 is missing the Vbur property\n",
      "BA2684 is missing the Vbur property\n",
      "Entry 511 was removed from plot data due to incomplete data\n",
      "Entry 604 was removed from plot data due to incomplete data\n",
      "Entry 967 was removed from plot data due to incomplete data\n",
      "Entry 1424 was removed from plot data due to incomplete data\n",
      "Entry 1565 was removed from plot data due to incomplete data\n",
      "Entry 1872 was removed from plot data due to incomplete data\n",
      "Entry 1960 was removed from plot data due to incomplete data\n",
      "Entry 2321 was removed from plot data due to incomplete data\n",
      "Entry 2458 was removed from plot data due to incomplete data\n",
      "Entry 2464 was removed from plot data due to incomplete data\n",
      "Entry 2684 was removed from plot data due to incomplete data\n",
      "11 entries were removed due to incomplete data\n"
     ]
    }
   ],
   "source": [
    "#This block finds the relevant carbon atoms by finding the carbon atom closest to the atom of interest defined at the top of this notebook. Based on the closest carbon atom indeces\n",
    "# it compiles a plot_data dictionary which only holds relevant data.\n",
    "\n",
    "closest_carbons = {}\n",
    "\n",
    "for key in collected_data.keys():\n",
    "    \n",
    "    os.chdir(str(key) + \"/orca\")\n",
    "    coordinates = get_text_from_file(file_prefix + \"_\" + str(key) + \".xyz\")\n",
    "\n",
    "    #number_of_atoms = int(coordinates[0].split()[0])\n",
    "\n",
    "    coordinates.pop(0)\n",
    "    coordinates.pop(0)\n",
    "\n",
    "    atom_coord = [] # will hold the Vec3D coordinates of the boron\n",
    "    min_dist = 9999999999999 # will hold the coordinates of the carbon closest to the boron\n",
    "    carbon_index = -1\n",
    "\n",
    "    for i in range(len(coordinates)):\n",
    "\n",
    "        arr = coordinates[i].split()\n",
    "        if arr[0] == X:\n",
    "            arr.pop(0)\n",
    "            atom_coord = [float(arr[0]), float(arr[1]), float(arr[2])]\n",
    "            break\n",
    "\n",
    "    for i in range(len(coordinates)):\n",
    "        arr = coordinates[i].split()\n",
    "\n",
    "        if arr[0] == \"C\":\n",
    "        \n",
    "            vec3d = [atom_coord[0] - float(arr[1]), atom_coord[1] - float(arr[2]), atom_coord[2] - float(arr[3])]\n",
    "\n",
    "            length = math.sqrt((vec3d[0] * vec3d[0]) + (vec3d[1] * vec3d[1]) + (vec3d[2] * vec3d[2]))\n",
    "\n",
    "            if length < min_dist:\n",
    "                min_dist = length\n",
    "                carbon_index = i\n",
    "    \n",
    "    closest_carbons[key] = {\n",
    "        \n",
    "        \"dis\": min_dist,\n",
    "        \"index\": carbon_index\n",
    "\n",
    "    }\n",
    "\n",
    "    os.chdir(\"../../\")\n",
    "\n",
    "\n",
    "\n",
    "plot_data = {}\n",
    "\n",
    "incomplete_entries = []\n",
    "\n",
    "for key in collected_data.keys():\n",
    "    plot_data[key] = {}\n",
    "    index = closest_carbons[key][\"index\"]\n",
    "    for prop in collected_data[0].keys():\n",
    "        if prop in collected_data[key].keys():\n",
    "            if type(collected_data[key][prop]) is not dict:\n",
    "                plot_data[key][prop] = collected_data[key][prop]\n",
    "            elif type(collected_data[key][prop]) is dict:\n",
    "                plot_data[key][prop] = collected_data[key][prop][index][\"value\"]\n",
    "        else:\n",
    "            print(f\"BA{key} is missing the {prop} property\")\n",
    "            if key not in incomplete_entries:\n",
    "                incomplete_entries.append(key)\n",
    "\n",
    "    plot_data[key][\"CB DIST\"] = closest_carbons[key][\"dis\"]\n",
    "\n",
    "for entry in incomplete_entries:\n",
    "    print(f\"Entry {entry} was removed from plot data due to incomplete data\")\n",
    "    plot_data.pop(entry)\n",
    "    smiles.pop(entry)\n",
    "\n",
    "print(f\"{len(incomplete_entries)} entries were removed due to incomplete data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the plot data dictionary is converted in to a .csv file. Make sure to define a name for the file.\n",
    "\n",
    "column_titles = []\n",
    "\n",
    "for key in plot_data[0].keys():\n",
    "    column_titles.append(key)\n",
    "\n",
    "file = f\"{output_name}.csv\"  # <------ DEFINE A NAME FOR THE CSV DATA FILE\n",
    "\n",
    "with open(file, \"w\") as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=column_titles)\n",
    "    writer.writeheader()\n",
    "    for key in plot_data.keys():\n",
    "        writer.writerow(plot_data[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d93dec808c00983fdd852abe8d4dfed384449693aef21e77d0e0472f25b56f66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
